{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "304e7b62-f9ac-40b4-baf2-08635b118f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#将fna文件内容转化为序列\n",
    "output_file_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics/1.txt'\n",
    "\n",
    "with open('/home/nusri/下载/dna_feat/dataset/probiotics_fna/GCF_002356135.1_ASM235613v1_genomic.fna', 'r') as seq:\n",
    "    lines = seq.readlines()\n",
    "    part = ''\n",
    "    for line in lines[1:]:\n",
    "        part += line.strip()\n",
    "        \n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        output_file.write(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ebb0a-eef5-4bdd-a2ba-7859a93da252",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/nonprobiotics_fna'\n",
    "\n",
    "output_file_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics'\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        with open(file_path, 'w') as seq:\n",
    "            lines = seq.lines[1:]\n",
    "            line.strip()\n",
    "            \n",
    "            output_file.write(lines.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5875685c-6629-4e58-a21d-2554abbdfd8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'lines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# with open(output_file_path, 'w') as output_file:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     for filename in os.listdir(folder_path):\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         file_path = os.path.join(folder_path, filename)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m seq:\n\u001b[0;32m---> 13\u001b[0m     lines \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mlines[\u001b[38;5;241m1\u001b[39m:]  \n\u001b[1;32m     14\u001b[0m     output_file\u001b[38;5;241m.\u001b[39mwrite(lines\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'lines'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/nonprobiotics_fna'\n",
    "\n",
    "output_file_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics'\n",
    "\n",
    "file_path = '/home/nusri/下载/dna_feat/dataset/nonprobiotics_fna/GCA_002211645.1_ASM221164v1_genomic.fna'\n",
    "\n",
    "file_name = ''\n",
    "# with open(output_file_path, 'w') as output_file:\n",
    "#     for filename in os.listdir(folder_path):\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "with open(file_path, 'w') as output_file:\n",
    "    lines = seq.lines[1:]  \n",
    "    output_file.write(lines.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7071274d-9aad-4c0a-811a-06b6b883ade9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db464fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def combine_DNA_seq(folder_path, result_folder_path):\n",
    "    os.makedirs(result_folder_path, exist_ok=True)\n",
    "    dirs = [path for path in os.listdir(folder_path) if path.endswith('fna')]\n",
    "    for input_file in tqdm(dirs):\n",
    "        with open(os.path.join(folder_path, input_file), 'r') as seq:\n",
    "            file_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "            lines = seq.readlines()\n",
    "            part = ''\n",
    "            for line in lines[1:]:\n",
    "                if line[0] == '>':\n",
    "                    break\n",
    "                part += line.strip()\n",
    "\n",
    "            \n",
    "            output_file_path = os.path.join(result_folder_path, f'{file_name}.txt')\n",
    "            with open(output_file_path, 'w') as output_file:\n",
    "                output_file.write(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94945c4-5c7e-4102-895d-665c0897ea60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405/405 [00:08<00:00, 48.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#创建nonprobiotics的序列文档\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/nonprobiotics_fna'\n",
    "result_folder_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics'\n",
    "\n",
    "combine_DNA_seq(folder_path, result_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1660c368-c4b5-4ad8-b537-f886f0e92f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:02<00:00, 91.21it/s] \n"
     ]
    }
   ],
   "source": [
    "#创建probiotics的序列文档\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/probiotics_fna'\n",
    "result_folder_path = '/home/nusri/下载/dna_feat/dataset/merged_probiotics'\n",
    "\n",
    "combine_DNA_seq(folder_path, result_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2937e-6738-4fa4-894f-8a51705e5cbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_seq(k, chars, current_string, results):\n",
    "    if k == 0:\n",
    "        results.append(current_string)\n",
    "        return\n",
    "    for char in chars:\n",
    "        generate_seq(k - 1, chars, current_string + char, results)\n",
    "\n",
    "#生成所有k-mer序列\n",
    "def all_possible_seq(k, chars):\n",
    "    results = []\n",
    "    generate_seq(k, chars, '', results)\n",
    "    return results\n",
    "\n",
    "dna_list = ['A', 'G', 'T', 'C']\n",
    "\n",
    "with open('/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics/2.txt', 'r') as seqs:\n",
    "    dna_seq = seqs.read()\n",
    "\n",
    "#创建kmer序列与对应tf的字典\n",
    "def get_dict(seq):\n",
    "    curr_dict = {}\n",
    "    for k in range(2, 7):\n",
    "        dna_segs = all_possible_seq(k, dna_list)      #k-mer序列\n",
    "        new_dict = {seg:0 for seg in dna_segs}        #创建一个初始字典，key为k-mer序列，value为0\n",
    "        curr_dict.update(new_dict)                    #在k值更新之后更新字典\n",
    "        all_occur = len(seq) - k + 1                  #k-mer序列的数量\n",
    "        for x in range(all_occur):                    #计算每个k-mer序列的出现次数\n",
    "            key = seq[x: x+k]                         \n",
    "            curr_dict[key] += 1\n",
    "        curr_dict = {k:v for k,v in curr_dict.items()}#字典储存在curr_dict \n",
    "\n",
    "    for key in curr_dict.keys():                      \n",
    "        l = len(seq) - len(key) + 1\n",
    "        curr_dict[key] = curr_dict[key] / l           #计算tf\n",
    "    return(curr_dict)\n",
    "\n",
    "def feat2str(int_float_dict):\n",
    "    feat_str = ''\n",
    "    for index, value in int_float_dict.items():\n",
    "        feat_str += str(index) + ':' + str(value) + ' '  \n",
    "    #feat_str = str(label) + '\\t' + feat_str \n",
    "    return feat_str\n",
    "    \n",
    "def main(seq):\n",
    "    res_dict = ''\n",
    "    feat_dict = get_dict(seq)\n",
    "    #给kmer序列标号并创建字典\n",
    "    index_ATCG_map = {ATCG: int(i) for i, ATCG in enumerate(feat_dict.keys())}\n",
    "    #创建index和tf的字典\n",
    "    feat_dict = {index_ATCG_map[ATCG]: value for i, (ATCG, value) in enumerate(feat_dict.items())}\n",
    "    res_dict += feat2str(feat_dict)\n",
    "    return res_dict\n",
    "\n",
    "main(dna_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61f54a1-b31b-4569-87c6-beb32e743c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "#生成所有k-mer序列\n",
    "dna_list = ['A', 'G', 'T', 'C']\n",
    "\n",
    "def all_possible_seq(k):\n",
    "    \n",
    "    def generate_seq(k, chars, current_string, results):\n",
    "        if k == 0:\n",
    "            results.append(current_string)\n",
    "            return\n",
    "        for char in chars:\n",
    "            generate_seq(k - 1, chars, current_string + char, results)\n",
    "\n",
    "    results = []\n",
    "    generate_seq(k, dna_list, '', results)\n",
    "    return results\n",
    "\n",
    "ambiguity_symbol_dict = {\n",
    "    'A': ['A'], 'T': ['T'], 'C': ['C'],'G': ['G'],\n",
    "    'W': ['A', 'T'], 'S': ['C', 'G'], \n",
    "    'M': ['A', 'C'], 'K': ['G', 'T'], \n",
    "    'R': ['A', 'G'], 'Y': ['C', 'T'],\n",
    "    'B': ['C', 'G', 'T'], 'D': ['A', 'G', 'T'], \n",
    "    'H': ['A', 'C', 'T'], 'V': ['A', 'C', 'G'], \n",
    "    'N': ['A', 'C', 'G', 'T']\n",
    "}\n",
    "\n",
    "def nucleic_acid_count(dna_seg):\n",
    "    result = {'A': 0.0, 'T': 0.0, 'C': 0.0, 'G': 0.0}\n",
    "\n",
    "    for char in dna_seg:\n",
    "        possib_chars = ambiguity_symbol_dict[char]\n",
    "        possib_chars_num = len(possib_chars)\n",
    "        # e.g. 'W':['A', 'T'] --> 'A':0.5, 'T':0.5\n",
    "        #      'D':['A', 'G', 'T'] --> 'A':1/3, 'G':1/3, 'T':1/3\n",
    "        #      'A':['A'] --> 'A':1/1\n",
    "        for pc in possib_chars:\n",
    "            result[pc] += 1/possib_chars_num\n",
    "        \n",
    "    return Counter(result)\n",
    "\n",
    "# Test \n",
    "# nucleic_acid_count('AWCBN')\n",
    "\n",
    "#创建kmer序列与对应tf的字典\n",
    "def get_dict(seq):\n",
    "    curr_dict = Counter()\n",
    "    for k in range(2, 5):\n",
    "        dna_segs = all_possible_seq(k)                #k-mer序列\n",
    "        new_dict = {seg:0 for seg in dna_segs}        #创建一个初始字典，key为k-mer序列，value为0\n",
    "        curr_dict += new_dict                         #在k值更新之后更新字典\n",
    "        all_occur = len(seq) - k + 1                  #k-mer序列的数量\n",
    "        for x in range(all_occur):                    #计算每个k-mer序列的出现次数\n",
    "            key = seq[x: x+k]                         \n",
    "            # curr_dict[key] += 1\n",
    "            # curr_dict.update({ key: curr_dict[key]+1 })\n",
    "            # curr_dict.update({ key1: curr_dict[key]+0.5, key2: curr_dict[key]+0.5 })\n",
    "            # curr_dict.update({ lambda N: keyN: curr_dict[key]+1/N })\n",
    "            curr_dict += nucleic_acid_count(dna_seg=key)\n",
    "        \n",
    "        # curr_dict = {k:v for k,v in curr_dict.items()}#字典储存在curr_dict \n",
    "\n",
    "    for key in curr_dict.keys():                      \n",
    "        l = len(seq) - len(key) + 1\n",
    "        curr_dict[key] = curr_dict[key] / l           #计算tf\n",
    "    return(curr_dict)\n",
    "\n",
    "def feat2str(int_float_dict):\n",
    "    feat_str = ''\n",
    "    for index, value in int_float_dict.items():\n",
    "        feat_str += str(index) + ':' + str(value) + ' '  \n",
    "    #feat_str = str(label) + '\\t' + feat_str \n",
    "    return feat_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c52f511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [05:43, 24.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m feat_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     feat_dict \u001b[39m=\u001b[39m get_dict(seq)\n\u001b[1;32m     19\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mERROR: \u001b[39m\u001b[39m'\u001b[39m, filename)\n",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m, in \u001b[0;36mget_dict\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m     57\u001b[0m         key \u001b[39m=\u001b[39m seq[x: x\u001b[39m+\u001b[39mk]                         \n\u001b[1;32m     58\u001b[0m         \u001b[39m# curr_dict[key] += 1\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[39m# curr_dict.update({ key: curr_dict[key]+1 })\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[39m# curr_dict.update({ key1: curr_dict[key]+0.5, key2: curr_dict[key]+0.5 })\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[39m# curr_dict.update({ lambda N: keyN: curr_dict[key]+1/N })\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m         curr_dict \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m nucleic_acid_count(dna_seg\u001b[39m=\u001b[39mkey)\n\u001b[1;32m     64\u001b[0m     \u001b[39m# curr_dict = {k:v for k,v in curr_dict.items()}#字典储存在curr_dict \u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m curr_dict\u001b[39m.\u001b[39mkeys():                      \n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mnucleic_acid_count\u001b[0;34m(dna_seg)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# e.g. 'W':['A', 'T'] --> 'A':0.5, 'T':0.5\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[39m#      'D':['A', 'G', 'T'] --> 'A':1/3, 'G':1/3, 'T':1/3\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[39m#      'A':['A'] --> 'A':1/1\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39mfor\u001b[39;00m pc \u001b[39min\u001b[39;00m possib_chars:\n\u001b[0;32m---> 41\u001b[0m         result[pc] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mpossib_chars_num\n\u001b[1;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m Counter(result)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics'\n",
    "label = 0\n",
    "dirs = [path for path in os.listdir(folder_path) if path.endswith('txt')]\n",
    "seq_list = []\n",
    "filename_list =[]\n",
    "# for input_file in dirs[:3]:\n",
    "for input_file in dirs:\n",
    "    with open(os.path.join(folder_path, input_file)) as seqs:\n",
    "        dna_seq = seqs.read()\n",
    "        seq_list.append(dna_seq)\n",
    "        filename_list.append(input_file)\n",
    "\n",
    "\n",
    "feat_str_list =[]\n",
    "for seq, filename in tqdm(zip(seq_list,filename_list),total=len(seq_list)):\n",
    "    feat_str = ''\n",
    "    try:\n",
    "        feat_dict = get_dict(seq)\n",
    "    except Exception as e:\n",
    "        print('ERROR: ', filename)\n",
    "        raise('ERROR')\n",
    "    #给kmer序列标号并创建字典\n",
    "    index_ATCG_map = {ATCG: int(i) for i, ATCG in enumerate(feat_dict.keys())}\n",
    "    #创建index和tf的字典\n",
    "    feat_dict = {index_ATCG_map[ATCG]: value for i, (ATCG, value) in enumerate(feat_dict.items())}\n",
    "    feat_str += feat2str(feat_dict)\n",
    "    feat_str_list.append(feat_str)\n",
    "\n",
    "with open('result_nonprobio.tsv', 'w') as f:\n",
    "    for feat_str in feat_str_list:\n",
    "        f.write(label + '\\t' + feat_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa422b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [1:16:19, 117.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m feat_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     feat_dict \u001b[39m=\u001b[39m get_dict(seq)\n\u001b[1;32m     19\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mERROR: \u001b[39m\u001b[39m'\u001b[39m, filename)\n",
      "Cell \u001b[0;32mIn[6], line 62\u001b[0m, in \u001b[0;36mget_dict\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m     57\u001b[0m         key \u001b[39m=\u001b[39m seq[x: x\u001b[39m+\u001b[39mk]                         \n\u001b[1;32m     58\u001b[0m         \u001b[39m# curr_dict[key] += 1\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[39m# curr_dict.update({ key: curr_dict[key]+1 })\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[39m# curr_dict.update({ key1: curr_dict[key]+0.5, key2: curr_dict[key]+0.5 })\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[39m# curr_dict.update({ lambda N: keyN: curr_dict[key]+1/N })\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m         curr_dict \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m nucleic_acid_count(dna_seg\u001b[39m=\u001b[39mkey)\n\u001b[1;32m     64\u001b[0m     \u001b[39m# curr_dict = {k:v for k,v in curr_dict.items()}#字典储存在curr_dict \u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m curr_dict\u001b[39m.\u001b[39mkeys():                      \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics'\n",
    "label = 0\n",
    "dirs = [path for path in os.listdir(folder_path) if path.endswith('txt')]\n",
    "seq_list = []\n",
    "filename_list =[]\n",
    "# for input_file in dirs[:3]:\n",
    "for input_file in dirs:\n",
    "    with open(os.path.join(folder_path, input_file)) as seqs:\n",
    "        dna_seq = seqs.read()\n",
    "        seq_list.append(dna_seq)\n",
    "        filename_list.append(input_file)\n",
    "\n",
    "\n",
    "feat_str_list =[]\n",
    "for seq, filename in tqdm(zip(seq_list,filename_list)):\n",
    "    feat_str = ''\n",
    "    try:\n",
    "        feat_dict = get_dict(seq)\n",
    "    except Exception as e:\n",
    "        print('ERROR: ', filename)\n",
    "        raise('ERROR')\n",
    "    #给kmer序列标号并创建字典\n",
    "    index_ATCG_map = {ATCG: int(i) for i, ATCG in enumerate(feat_dict.keys())}\n",
    "    #创建index和tf的字典\n",
    "    feat_dict = {index_ATCG_map[ATCG]: value for i, (ATCG, value) in enumerate(feat_dict.items())}\n",
    "    feat_str += feat2str(feat_dict)\n",
    "    feat_str_list.append(feat_str)\n",
    "\n",
    "with open('result_nonprobio.tsv', 'w') as f:\n",
    "    for feat_str in feat_str_list:\n",
    "        f.write(label + '\\t' + feat_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ed3945-e7d8-4412-a1f5-05d572737ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'dataset/nonprobiotics_fna/.ipynb_checkpoints']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "list(glob('**/.ipynb_checkpoints', recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ee3d77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['AA', 'AT']\n",
      "['AAC', 'ATC']\n",
      "['AACC', 'AACG', 'AACT', 'ATCC', 'ATCG', 'ATCT']\n",
      "['AACCA', 'AACCC', 'AACCG', 'AACCT', 'AACGA', 'AACGC', 'AACGG', 'AACGT', 'AACTA', 'AACTC', 'AACTG', 'AACTT', 'ATCCA', 'ATCCC', 'ATCCG', 'ATCCT', 'ATCGA', 'ATCGC', 'ATCGG', 'ATCGT', 'ATCTA', 'ATCTC', 'ATCTG', 'ATCTT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AACCA',\n",
       " 'AACCC',\n",
       " 'AACCG',\n",
       " 'AACCT',\n",
       " 'AACGA',\n",
       " 'AACGC',\n",
       " 'AACGG',\n",
       " 'AACGT',\n",
       " 'AACTA',\n",
       " 'AACTC',\n",
       " 'AACTG',\n",
       " 'AACTT',\n",
       " 'ATCCA',\n",
       " 'ATCCC',\n",
       " 'ATCCG',\n",
       " 'ATCCT',\n",
       " 'ATCGA',\n",
       " 'ATCGC',\n",
       " 'ATCGG',\n",
       " 'ATCGT',\n",
       " 'ATCTA',\n",
       " 'ATCTC',\n",
       " 'ATCTG',\n",
       " 'ATCTT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguity_symbol_dict = {\n",
    "    'A': ['A'], 'T': ['T'], 'C': ['C'], 'G': ['G'],\n",
    "    'W': ['A', 'T'], 'S': ['C', 'G'], 'M': ['A', 'C'], \n",
    "    'K': ['G', 'T'], 'R': ['A', 'G'], 'Y': ['C', 'T'], \n",
    "    'B': ['C', 'G', 'T'], 'D': ['A', 'G', 'T'], \n",
    "    'H': ['A', 'C', 'T'], 'V': ['A', 'C', 'G'],\n",
    "    'N': ['A', 'C', 'G', 'T']\n",
    "}\n",
    "\n",
    "def nucleic_acid_expand(dna_seq):\n",
    "    results = ['']\n",
    "    for base in dna_seq:\n",
    "        results = [ seq + new_seq \n",
    "                  for seq in results \n",
    "                    for new_seq in ambiguity_symbol_dict[base]]\n",
    "        print(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "nucleic_acid_expand('AWCBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54265e30-5da5-4347-a610-3de0fb4a597c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "file = '/home/nusri/下载/dna_feat/dataset/probiotics_fna/GCA_000006965.1_ASM696v1_genomic.fna'\n",
    "with open(file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "#new_lines = [line.strip() if not line.startswith('>') else '\\n' for line in lines]\n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    if line.startswith('>'):\n",
    "        new_lines.append('\\n')\n",
    "    else:\n",
    "        new_lines.append(line)\n",
    "paragraphs = ''.join(new_lines).split('\\n\\n')\n",
    "for i, paragraph in enumerate(paragraphs):\n",
    "    if paragraph.strip():\n",
    "        paragraph_filename = file.strip('.fna')\n",
    "        paragraph_filename += f'_{i}.txt'\n",
    "        with open(paragraph_filename, 'w') as paragraph_file:\n",
    "            paragraph_file.write(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed1dd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paragraph_filename = '/home/nusri/下载/dna_feat/dataset/probiotics_fna/GCA_000006965.1_ASM696v1_genomic_83649.txt'\n",
    "if os.path.exists(paragraph_filename):\n",
    "    os.remove(paragraph_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51b81708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCA_000192705.1_ASM19270v1_genomic.fna', 'GCA_001941785.1_ASM194178v1_genomic.fna', 'GCA_000189515.1_ASM18951v1_genomic.fna', 'GCA_000236475.1_ASM23647v1_genomic.fna', 'GCA_000572065.1_TH982VE_genomic.fna', 'GCA_000262325.2_ASM26232v2_genomic.fna', 'GCA_000014545.1_ASM1454v1_genomic.fna', 'GCA_000836595.1_1F8CTVE_genomic.fna', 'GCA_000182835.1_ASM18283v1_genomic.fna', 'GCA_000418515.1_ASM41851v1_genomic.fna', 'GCA_001272315.2_ASM127231v2_genomic.fna', 'GCA_002078895.1_ASM207889v1_genomic.fna', 'GCA_002078955.1_ASM207895v1_genomic.fna', 'GCA_000582665.1_ASM58266v1_genomic.fna', 'GCA_000521305.1_TH1436VE_genomic.fna', 'GCF_002356135.1_ASM235613v1_genomic.fna', 'GCA_000961015.1_ASM96101v1_genomic.fna', 'GCA_002075105.1_ASM207510v1_genomic.fna', 'GCA_002813615.1_ASM281361v1_genomic.fna', 'GCA_002078475.2_ASM207847v2_genomic.fna', 'GCA_002442835.1_ASM244283v1_genomic.fna', 'GCA_000410995.1_ASM41099v1_genomic.fna', 'GCA_002148215.1_ASM214821v1_genomic.fna', 'GCA_000186085.1_ASM18608v1_genomic.fna', 'GCA_000196575.1_ASM19657v1_genomic.fna', 'GCA_000012905.2_ASM1290v2_genomic.fna', 'GCA_000248095.3_ASM24809v3_genomic.fna', 'GCA_000014485.1_ASM1448v1_genomic.fna', 'GCA_000155515.2_ASM15551v2_genomic.fna', 'GCF_002078615.2_ASM207861v2_genomic.fna', 'GCA_000025985.1_ASM2598v1_genomic.fna', 'GCA_002078495.1_ASM207849v1_genomic.fna', 'GCA_002079285.1_ASM207928v1_genomic.fna', 'GCA_000219455.1_ASM21945v1_genomic.fna', 'GCA_002201995.1_ASM220199v1_genomic.fna', 'GCA_002287905.1_ASM228790v1_genomic.fna', 'GCA_000392485.2_ASM39248v2_genomic.fna', 'GCA_002078415.1_ASM207841v1_genomic.fna', 'GCA_000175935.2_ASM17593v2_genomic.fna', 'GCA_000195575.1_ASM19557v1_genomic.fna', 'GCA_000194765.1_ASM19476v1_genomic.fna', 'GCA_002849955.1_ASM284995v1_genomic.fna', 'GCA_002078375.2_ASM207837v2_genomic.fna', 'GCF_001908455.1_ASM190845v1_genomic.fna', 'GCA_000829035.1_ASM82903v1_genomic.fna', 'GCA_000388095.2_LcY_assembly050913_genomic.fna', 'GCA_000219805.1_ASM21980v1_genomic.fna', 'GCA_000521325.1_MTH17CL396VE_genomic.fna', 'GCA_000195775.1_ASM19577v1_genomic.fna', 'GCA_000521285.1_TH1435VE_genomic.fna', 'GCA_002849935.1_ASM284993v1_genomic.fna', 'GCA_000008925.1_ASM892v1_genomic.fna', 'GCA_000025045.1_ASM2504v1_genomic.fna', 'GCA_000312685.1_ASM31268v1_genomic.fna', 'GCA_000318035.1_ASM31803v1_genomic.fna', 'GCA_000019245.3_ASM1924v3_genomic.fna', 'GCA_002105575.1_ASM210557v1_genomic.fna', 'GCA_000148815.2_ASM14881v1_genomic.fna', 'GCA_001646605.1_ASM164660v1_genomic.fna', 'GCA_000194785.1_ASM19478v1_genomic.fna', 'GCA_002078975.2_ASM207897v2_genomic.fna', 'GCA_001856165.1_IBB477v1_genomic.fna', 'GCA_000836675.1_TH985VE_genomic.fna', 'GCA_002078435.1_ASM207843v1_genomic.fna', 'GCA_000817975.1_ASM81797v1_genomic.fna', 'GCA_000478255.2_ASM47825v2_genomic.fna', 'GCA_001191565.1_ASM119156v1_genomic.fna', 'GCA_000214785.1_ASM21478v1_genomic.fna', 'GCA_000466785.3_ASM46678v3_genomic.fna', 'GCF_000479375.3_ASM47937v3_genomic.fna', 'GCA_000154765.2_ASM15476v2_genomic.fna', 'GCF_000400585.1_LcA_0213_genomic.fna', 'GCA_000014445.1_ASM1444v1_genomic.fna', 'GCA_000572095.1_TH1477VE_genomic.fna', 'GCA_000026185.1_ASM2618v1_genomic.fna', 'GCA_000359625.1_ASM35962v1_genomic.fna', 'GCA_000016325.1_ASM1632v1_genomic.fna', 'GCA_000010725.1_ASM1072v1_genomic.fna', 'GCA_002906875.1_ASM290687v1_genomic.fna', 'GCA_002078765.2_ASM207876v2_genomic.fna', 'GCA_900088425.1_A12_genomic.fna', 'GCF_000143435.1_ASM14343v1_genomic.fna', 'GCA_002078995.2_ASM207899v2_genomic.fna', 'GCA_000021325.1_ASM2132v1_genomic.fna', 'GCA_000014525.1_ASM1452v1_genomic.fna', 'GCA_000025965.1_ASM2596v1_genomic.fna', 'GCA_002849915.1_ASM284991v1_genomic.fna', 'GCA_000017965.1_ASM1796v1_genomic.fna', 'GCA_002078855.1_ASM207885v1_genomic.fna', 'GCA_000187705.1_ASM18770v1_genomic.fna', 'GCA_000006965.1_ASM696v1_genomic.fna', 'GCA_002078935.1_ASM207893v1_genomic.fna']\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/home/nusri/下载/dna_feat/dataset/probiotics_fna'\n",
    "paths = os.listdir(folder_path)\n",
    "file_list = []\n",
    "for path in paths:\n",
    "    counter = 0\n",
    "    with open(os.path.join(folder_path, path), 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('>'):\n",
    "                counter += 1\n",
    "    if counter >= 2:\n",
    "        file_list.append(path)\n",
    "\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7e66d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_duplicate_files(file, output_dir):\n",
    "#     with open(file, 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "#         #new_lines = [line.strip() if not line.startswith('>') else '\\n' for line in lines]\n",
    "#     new_lines = []\n",
    "#     for line in lines:\n",
    "#         if line.startswith('>'):\n",
    "#             new_lines.append('\\n')\n",
    "#         else:\n",
    "#             new_lines.append(line)\n",
    "#     paragraphs = ''.join(new_lines).split('\\n\\n')\n",
    "#     for i, paragraph in enumerate(paragraphs):\n",
    "#         if paragraph.strip():\n",
    "#             paragraph_filename = file.strip('.fna')\n",
    "#             paragraph_filename += f'_{i}.txt'\n",
    "#             output_filepath = os.path.join(output_dir, paragraph_filename)\n",
    "            \n",
    "#             with open(output_filepath, 'w') as output_file:\n",
    "#                 output_file.write(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8916afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_files(file, output_dir):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            new_lines.append('\\n')\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "\n",
    "    paragraphs = ''.join(new_lines).split('\\n\\n')\n",
    "\n",
    "    for i, paragraph in enumerate(paragraphs):\n",
    "        if paragraph.strip():\n",
    "            paragraph_filename = os.path.splitext(os.path.basename(file))[0]\n",
    "            paragraph_filename += f'_{i}.txt'\n",
    "            output_filepath = os.path.join(output_dir, paragraph_filename)\n",
    "            \n",
    "            with open(output_filepath, 'w') as output_file:\n",
    "                output_file.write(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f584baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/nusri/下载/dna_feat/dataset/probiotics_fna'\n",
    "output_dir = '/home/nusri/下载/dna_feat/dataset/single_seq_probiotic'\n",
    "file_path_list = []\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    file_path_list.append(file_path)\n",
    "#print(file_path_list)\n",
    "for fp in file_path_list:\n",
    "    get_duplicate_files(fp, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df1a1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/nusri/下载/dna_feat/dataset/nonprobiotics_fna'\n",
    "def del_file(folder_path, suffix):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(suffix):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            os.remove(filepath)\n",
    "for i in range(100):\n",
    "    suffix = f'_{i}.txt'\n",
    "    del_file(folder_path, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "500ae703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCA_000772485.1_ASM77248v1_genomic.fna', 'GCA_000262675.1_ASM26267v1_genomic.fna', 'GCA_001702095.1_ASM170209v1_genomic.fna', 'GCA_002843115.1_ASM284311v1_genomic.fna', 'GCA_001514435.1_ASM151443v1_genomic.fna', 'GCA_001244395.1_ASM124439v1_genomic.fna', 'GCA_000349795.1_ASM34979v1_genomic.fna', 'GCA_000023205.1_ASM2320v1_genomic.fna', 'GCA_000023585.1_ASM2358v1_genomic.fna', 'GCA_000092765.1_ASM9276v1_genomic.fna', 'GCA_000009045.1_ASM904v1_genomic.fna', 'GCA_001469775.1_ASM146977v1_genomic.fna', 'GCA_000006765.1_ASM676v1_genomic.fna', 'GCA_000468955.1_ASM46895v1_genomic.fna', 'GCA_000706705.1_ASM70670v1_genomic.fna', 'GCA_000165775.3_ASM16577v3_genomic.fna', 'GCA_001697265.1_ASM169726v1_genomic.fna', 'GCA_000525715.1_ASM52571v1_genomic.fna', 'GCA_000010145.1_ASM1014v1_genomic.fna', 'GCA_000092325.1_ASM9232v1_genomic.fna', 'GCA_002286215.1_ASM228621v1_genomic.fna', 'GCA_000971665.1_ASM97166v1_genomic.fna', 'GCA_000283495.2_ASM28349v2_genomic.fna', 'GCA_000006865.1_ASM686v1_genomic.fna', 'GCA_001308285.1_ASM130828v1_genomic.fna', 'GCA_000253395.1_ASM25339v1_genomic.fna', 'GCA_000143205.1_ASM14320v1_genomic.fna', 'GCA_000011365.1_ASM1136v1_genomic.fna', 'GCA_000277345.1_ASM27734v1_genomic.fna', 'GCA_000196555.1_ASM19655v1_genomic.fna', 'GCA_002000885.1_ASM200088v1_genomic.fna', 'GCF_000022965.1_ASM2296v1_genomic.fna', 'GCA_000014425.1_ASM1442v1_genomic.fna', 'GCA_001663795.1_ASM166379v1_genomic.fna', 'GCA_000269965.1_ASM26996v1_genomic.fna', 'GCA_002846155.1_ASM284615v1_genomic.fna', 'GCA_000009825.1_ASM982v1_genomic.fna', 'GCA_000020225.1_ASM2022v1_genomic.fna', 'GCA_004319685.1_ASM431968v1_genomic.fna', 'GCA_001725985.1_ASM172598v1_genomic.fna', 'GCA_000389675.2_ASM38967v2_genomic.fna', 'GCA_002201955.1_ASM220195v1_genomic.fna', 'GCA_000934625.1_ASM93462v1_genomic.fna', 'GCA_000013345.1_ASM1334v1_genomic.fna', 'GCA_001280285.1_ASM128028v1_genomic.fna', 'GCA_000344745.1_ASM34474v1_genomic.fna', 'GCA_002786555.1_ASM278655v1_genomic.fna', 'GCA_002443035.1_ASM244303v1_genomic.fna', 'GCA_000876545.1_ASM87654v1_genomic.fna', 'GCA_002286255.1_ASM228625v1_genomic.fna', 'GCA_002173715.1_ASM217371v1_genomic.fna', 'GCA_002202035.1_ASM220203v1_genomic.fna', 'GCA_000165905.1_ASM16590v1_genomic.fna', 'GCA_000496265.1_ASM49626v1_genomic.fna', 'GCA_001541905.1_ASM154190v1_genomic.fna', 'GCA_002804285.1_ASM280428v1_genomic.fna', 'GCA_000005845.2_ASM584v2_genomic.fna', 'GCA_000283615.1_ASM28361v1_genomic.fna', 'GCA_000019045.1_ASM1904v1_genomic.fna', 'GCA_000816205.1_ASM81620v1_genomic.fna', 'GCA_000021425.1_ASM2142v1_genomic.fna', 'GCA_001750745.1_ASM175074v1_genomic.fna', 'GCA_002804185.1_ASM280418v1_genomic.fna', 'GCA_000019965.1_ASM1996v1_genomic.fna', 'GCA_000022705.1_ASM2270v1_genomic.fna', 'GCA_000422165.1_ASM42216v1_genomic.fna', 'GCA_001446275.1_ASM144627v1_genomic.fna', 'GCA_000008065.1_ASM806v1_genomic.fna', 'GCA_000011845.1_ASM1184v1_genomic.fna', 'GCA_000026505.1_ASM2650v1_genomic.fna', 'GCA_002119645.1_ASM211964v1_genomic.fna', 'GCA_000020425.1_ASM2042v1_genomic.fna', 'GCA_000026485.1_ASM2648v1_genomic.fna', 'GCA_000155355.1_ASM15535v1_genomic.fna', 'GCA_001051015.2_ASM105101v2_genomic.fna', 'GCA_004114715.1_ASM411471v1_genomic.fna', 'GCA_003856735.1_ASM385673v1_genomic.fna', 'GCA_001705585.1_ASM170558v1_genomic.fna', 'GCA_001855705.1_ASM185570v1_genomic.fna', 'GCA_000220135.1_ASM22013v1_genomic.fna', 'GCA_001006025.1_ASM100602v1_genomic.fna', 'GCA_001953135.1_ASM195313v1_genomic.fna', 'GCA_001660525.1_ASM166052v1_genomic.fna', 'GCA_002012365.1_ASM201236v1_genomic.fna', 'GCA_002902825.1_ASM290282v1_genomic.fna', 'GCA_001446255.1_ASM144625v1_genomic.fna', 'GCA_000182875.1_ASM18287v1_genomic.fna', 'GCA_001465815.1_ASM146581v1_genomic.fna', 'GCA_002865565.1_ASM286556v1_genomic.fna', 'GCA_000344575.1_ASM34457v1_genomic.fna', 'GCA_001746265.2_ASM174626v2_genomic.fna', 'GCA_001008015.1_ASM100801v1_genomic.fna', 'GCA_000827065.1_ASM82706v1_genomic.fna', 'GCA_000414215.1_ASM41421v1_genomic.fna', 'GCA_001281305.1_ASM128130v1_genomic.fna', 'GCA_000227485.1_ASM22748v1_genomic.fna', 'GCA_000091725.1_ASM9172v1_genomic.fna', 'GCA_000277325.1_ASM27732v1_genomic.fna', 'GCA_000011825.1_ASM1182v1_genomic.fna', 'GCA_000015385.1_ASM1538v1_genomic.fna', 'GCA_000025245.1_ASM2524v1_genomic.fna', 'GCA_001514415.1_ASM151441v1_genomic.fna', 'GCA_004355265.1_ASM435526v1_genomic.fna', 'GCA_000224965.2_ASM22496v2_genomic.fna', 'GCA_900094135.1_ASM90009413v1_genomic.fna', 'GCF_000832905.1_ASM83290v1_genomic.fna', 'GCA_002192435.1_ASM219243v1_genomic.fna', 'GCA_002257625.1_ASM225762v1_genomic.fna', 'GCA_001723545.1_ASM172354v1_genomic.fna', 'GCA_000046845.1_ASM4684v1_genomic.fna', 'GCA_000196735.1_ASM19673v1_genomic.fna', 'GCA_000014505.1_ASM1450v1_genomic.fna', 'GCA_000014385.1_ASM1438v1_genomic.fna', 'GCA_002946455.1_ASM294645v1_genomic.fna', 'GCA_000397165.1_ASM39716v1_genomic.fna', 'GCA_001685375.1_ASM168537v1_genomic.fna', 'GCA_000471945.1_ASM47194v1_genomic.fna', 'GCF_000210515.1_ASM21051v1_genomic.fna', 'GCA_000014405.1_ASM1440v1_genomic.fna', 'GCA_000698885.1_ASM69888v1_genomic.fna', 'GCA_000699525.1_ASM69952v1_genomic.fna', 'GCA_000009425.1_ASM942v1_genomic.fna', 'GCA_001703495.1_ASM170349v1_genomic.fna', 'GCA_002173695.1_ASM217369v1_genomic.fna', 'GCA_000056065.1_ASM5606v1_genomic.fna', 'GCA_000010525.1_ASM1052v1_genomic.fna', 'GCA_000220885.1_ASM22088v1_genomic.fna', 'GCA_000818055.1_ASM81805v1_genomic.fna', 'GCA_002895225.1_ASM289522v1_genomic.fna', 'GCA_000191165.1_ASM19116v1_genomic.fna', 'GCA_000210755.1_ASM21075v1_genomic.fna', 'GCA_000699465.1_ASM69946v1_genomic.fna', 'GCA_001742205.1_ASM174220v1_genomic.fna', 'GCA_000196175.1_ASM19617v1_genomic.fna', 'GCA_001039495.1_ASM103949v1_genomic.fna', 'GCA_000011985.1_ASM1198v1_genomic.fna', 'GCA_000166315.1_ASM16631v1_genomic.fna', 'GCA_000145235.1_ASM14523v1_genomic.fna', 'GCA_000321395.1_ASM32139v1_genomic.fna', 'GCA_000807375.1_ASM80737v1_genomic.fna', 'GCA_002846075.1_ASM284607v1_genomic.fna', 'GCA_900205745.1_Lf_IMDO_130101_genomic.fna', 'GCA_000155375.1_ASM15537v1_genomic.fna', 'GCA_000309565.2_ASM30956v2_genomic.fna', 'GCA_002224305.1_ASM222430v1_genomic.fna', 'GCA_000265095.1_ASM26509v1_genomic.fna']\n"
     ]
    }
   ],
   "source": [
    "#文件中只包含一个序列的\n",
    "#益生菌\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/probiotics_fna'\n",
    "paths = os.listdir(folder_path)\n",
    "\n",
    "basename_list = []\n",
    "for path in paths:\n",
    "    counter = 0\n",
    "    with open(os.path.join(folder_path, path), 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('>'):\n",
    "                counter += 1\n",
    "    if counter == 1:\n",
    "        basename_list.append(path)\n",
    "\n",
    "print(basename_list)\n",
    "#print('number of probiotic files with single seq:', len(basename_list))\n",
    "\n",
    "#pathname_list \n",
    "pathname_list = []\n",
    "merged_folder_path = '/home/nusri/下载/dna_feat/dataset/merged_probiotics'\n",
    "for file in basename_list:\n",
    "    file = os.path.splitext(os.path.basename(file))[0]\n",
    "    file += '.txt'\n",
    "    file_path = os.path.join(merged_folder_path, file)\n",
    "    pathname_list.append(file_path)\n",
    "\n",
    "#print(len(pathname_list))\n",
    "\n",
    "import shutil\n",
    "\n",
    "def copy_file(file_list, destination_folder):\n",
    "    for file in file_list:\n",
    "        source_path = file\n",
    "        file_name = os.path.basename(file)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "\n",
    "destination_folder = '/home/nusri/下载/dna_feat/dataset/single_seq_probiotic'\n",
    "\n",
    "copy_file(pathname_list, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25158543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件中只包含一个序列的\n",
    "#非益生菌\n",
    "folder_path = '/home/nusri/下载/dna_feat/dataset/nonprobiotics_fna'\n",
    "paths = os.listdir(folder_path)\n",
    "\n",
    "basename_list = []\n",
    "for path in paths:\n",
    "    counter = 0\n",
    "    with open(os.path.join(folder_path, path), 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('>'):\n",
    "                counter += 1\n",
    "    if counter == 1:\n",
    "        basename_list.append(path)\n",
    "\n",
    "#print('number of nonprobiotic files with single seq:', len(basename_list))\n",
    "\n",
    "#pathname_list \n",
    "pathname_list = []\n",
    "merged_folder_path = '/home/nusri/下载/dna_feat/dataset/merged_nonprobiotics'\n",
    "for file in basename_list:\n",
    "    file = os.path.splitext(os.path.basename(file))[0]\n",
    "    file += '.txt'\n",
    "    file_path = os.path.join(merged_folder_path, file)\n",
    "    pathname_list.append(file_path)\n",
    "\n",
    "#print(len(pathname_list))\n",
    "destination_folder = '/home/nusri/下载/dna_feat/dataset/single_seq_nonprobiotic'\n",
    "copy_file(pathname_list, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "425f34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 632/632 [06:25<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "folder_name = '/home/nusri/下载/dna_feat/dataset/single_seq_probiotic'\n",
    "file_list = os.listdir(folder_name)\n",
    "for file in tqdm(file_list):\n",
    "    file_path = os.path.join(folder_name, file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        result = ''\n",
    "        for line in lines:\n",
    "            result += line.strip()\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(result)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862071cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/home/nusri/下载/dna_feat/dataset/single_seq_nonprobiotic/GCF_000007045.1_ASM704v1_genomic.txt'\n",
    "with open(file_name, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    result = ''\n",
    "    for line in lines:\n",
    "        result += line.strip()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26931d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [227, 188, 306, 93, 298, 113, 307, 318, 177, 156, 235, 52, 264, 97, 60, 147, 216, 187, 212, 180, 226, 124, 126, 4, 259, 158, 134, 178, 50, 132, 115, 24, 114, 262, 107, 328, 163, 213, 220, 185, 191, 232, 35, 281, 275, 43, 139, 98, 257, 34, 170, 6, 9, 72, 12, 11, 14, 244, 3, 219, 308, 292, 49, 95, 121, 256, 150, 164, 62, 274, 294, 159, 218, 269, 116, 273, 320, 88, 141, 271, 51, 245, 171, 152, 133, 8, 326, 40, 27, 242, 142, 112, 278, 313, 288, 64, 253, 57, 102, 258, 222, 25, 153, 42, 248, 280, 20, 208, 1, 19, 104, 217, 29, 267, 70, 99, 137, 38, 125, 155, 31, 290, 154, 224, 87, 190, 223, 283, 140, 36, 254, 230, 66, 236, 252, 192, 160, 91, 200, 168, 215, 202, 172, 214, 247, 239, 136, 63, 32, 261, 325, 122, 324, 148, 221, 82, 96, 296, 56, 48, 2, 41, 76, 145, 69, 146, 157]\n",
    "max(arr), min(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e518b5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([4**i for i in range(2, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c3c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
